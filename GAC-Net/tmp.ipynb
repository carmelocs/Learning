{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath('.')\n",
    "BATCH_SIZE = 4\n",
    "# modelnet_dataset = ModelNetDataset(root=BASE_DIR)\n",
    "# modelnet_dataloader = DataLoader(modelnet_dataset, batch_size=BATCH_SIZE)\n",
    "# for (modelnet_pc, modelnet_label) in modelnet_dataloader:\n",
    "#     break\n",
    "\n",
    "s3dis_dataset = S3DISDataset(root=BASE_DIR)\n",
    "\n",
    "s3dis_dataloader = DataLoader(s3dis_dataset, batch_size=BATCH_SIZE)\n",
    "for (s3dis_pc, s3dis_label) in s3dis_dataloader:\n",
    "    break\n",
    "pc_dataset = s3dis_dataset\n",
    "\n",
    "point_feature = PointFeature(num_point=pc_dataset.num_points,\n",
    "                                global_feature=False)\n",
    "cls_net = PointNetCls(num_class=pc_dataset.num_classes,\n",
    "                        num_point=pc_dataset.num_points)\n",
    "seg_net = PointNetSeg(num_class=pc_dataset.num_classes,\n",
    "                        num_point=pc_dataset.num_points)\n",
    "segfc_net = PointNetSegFC(num_class=pc_dataset.num_classes,\n",
    "                            num_point=pc_dataset.num_points)\n",
    "\n",
    "\n",
    "# feature = point_feature(modelnet_pc)\n",
    "\n",
    "# seg_fc = segfc_net(modelnet_pc)\n",
    "\n",
    "# output = cls_net(modelnet_pc)\n",
    "# print(output.shape)\n",
    "# pred_num = output.argmax(dim=1)\n",
    "# for i in range(4):\n",
    "#     print(f'Item {i+1}: {modelnet_dataset.class_names[pred_num[i]]}')\n",
    "\n",
    "# print(pred_num.shape, modelnet_label.shape)\n",
    "\n",
    "# correct = (pred_num == modelnet_label.squeeze()).sum().item()\n",
    "# print(correct)\n",
    "\n",
    "# seg = seg_net(modelnet_pc)\n",
    "# print(seg.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(2.5847, grad_fn=<NllLossBackward>)\ntensor(2.2747, grad_fn=<NllLossBackward>)\ntensor(2.0795, grad_fn=<NllLossBackward>)\n"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(seg_net.parameters(), lr=0.0001)\n",
    "i=0\n",
    "while True:\n",
    "    optimizer.zero_grad()\n",
    "    seg = seg_net(s3dis_pc)\n",
    "    loss = F.nll_loss(seg.view(-1, 13), s3dis_label.view(-1).long())\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    i+=1\n",
    "    if i >2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length of training dataset: 19898\nLength of testing dataset: 3687\nNumber of classes: 13\n"
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "from dataset import ModelNetDataset, S3DISDataset\n",
    "import os\n",
    "\n",
    "BASE_DIR = os.path.dirname('.')\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "WORKERS = 0\n",
    "\n",
    "dataset = S3DISDataset(root=BASE_DIR)\n",
    "test_dataset = S3DISDataset(root=BASE_DIR, train=False)\n",
    "\n",
    "dataloader = data.DataLoader(dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True,\n",
    "                            num_workers=WORKERS)\n",
    "\n",
    "NUM_CLASSES = dataset.num_classes\n",
    "NUM_POINTS = dataset.num_points\n",
    "\n",
    "test_dataloader = data.DataLoader(test_dataset,\n",
    "                                   batch_size=BATCH_SIZE,\n",
    "                                   shuffle=True,\n",
    "                                   num_workers=WORKERS)\n",
    "\n",
    "print(f'Length of training dataset: {len(dataset)}')\n",
    "print(f'Length of testing dataset: {len(test_dataset)}')\n",
    "num_classes = dataset.num_classes\n",
    "print(f'Number of classes: {num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of batches: 4975\nEpoch: 0, iter: 0, train loss: 2.613, accuracy:10.059%\nEpoch: 0, iter: 1, train loss: 2.517, accuracy:13.843%\nEpoch: 0, iter: 2, train loss: 2.141, accuracy:36.572%\nEpoch: 0, iter: 3, train loss: 2.169, accuracy:36.292%\nEpoch: 0, iter: 4, train loss: 2.153, accuracy:33.331%\nEpoch: 0, iter: 5, train loss: 2.109, accuracy:39.001%\nEpoch: 0, iter: 6, train loss: 1.869, accuracy:52.997%\nEpoch: 0, iter: 7, train loss: 2.137, accuracy:33.508%\nEpoch: 0, iter: 8, train loss: 1.888, accuracy:47.296%\nEpoch: 0, iter: 9, train loss: 1.933, accuracy:48.126%\n\nEpoch: 0, iter: 9, test loss: 2.323, accuracy:14.154%\n\nEpoch: 0, iter: 10, train loss: 1.820, accuracy:48.828%\nEpoch: 0, iter: 11, train loss: 1.945, accuracy:37.354%\nEpoch: 0, iter: 12, train loss: 1.658, accuracy:49.774%\nEpoch: 0, iter: 13, train loss: 1.159, accuracy:78.772%\nEpoch: 0, iter: 14, train loss: 1.643, accuracy:55.438%\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-250-c64eec2e62b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mpred_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from model import PointNetCls, PointNetSeg\n",
    "\n",
    "net = PointNetSeg(num_class=NUM_CLASSES, num_point=NUM_POINTS)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "num_batch = int(len(dataset) / BATCH_SIZE) \\\n",
    "    if len(dataset) % BATCH_SIZE == 0 \\\n",
    "    else int(len(dataset) / BATCH_SIZE)+1\n",
    "print(f'Number of batches: {num_batch}')\n",
    "\n",
    "for epoch in range(2):\n",
    "    for i, (point_cloud, label) in enumerate(dataloader):\n",
    "        label = label.view(-1).long()\n",
    "        if torch.cuda.is_available():\n",
    "            point_cloud, label = point_cloud.cuda(), label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        net = net.train()\n",
    "        pred = net(point_cloud)\n",
    "        pred = pred.view(-1, NUM_CLASSES)\n",
    "        loss = F.nll_loss(pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred_num = pred.argmax(dim=1)\n",
    "        correct = (pred_num == label).sum().item()\n",
    "        print(f'Epoch: {epoch}, iter: {i}, train loss: {loss.item():.3f}, \\\n",
    "accuracy:{100*correct/(BATCH_SIZE*NUM_POINTS):.3f}%')\n",
    "\n",
    "        if i % 10 == 9:\n",
    "            j, (test_points, test_labels) = next(enumerate(test_dataloader))\n",
    "            test_labels = test_labels.view(-1).long()\n",
    "            if torch.cuda.is_available():\n",
    "                test_points, test_labels = test_points.cuda(\n",
    "                ), test_labels.cuda()\n",
    "            net = net.eval()\n",
    "            pred = net(test_points)\n",
    "            pred = pred.view(-1, NUM_CLASSES)\n",
    "            loss = F.nll_loss(pred, test_labels)\n",
    "            pred_num = pred.argmax(dim=1)\n",
    "            correct = (pred_num == test_labels).sum().item()\n",
    "            print(\n",
    "                f'\\nEpoch: {epoch}, iter: {i}, test loss: {loss.item():.3f}, \\\n",
    "accuracy:{100*correct/(BATCH_SIZE*NUM_POINTS):.3f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def square_distance(src, dst):\n",
    "    '''\n",
    "    Input:\n",
    "        src: [B, N, C]\n",
    "        dst: [B, M, C]\n",
    "    Retrun:\n",
    "        dist: [B, N, M]\n",
    "    '''\n",
    "\n",
    "    B, N, C = src.shape\n",
    "    _, M, _ = dst.shape\n",
    "\n",
    "    dist = -2 * torch.matmul(src, dst.permute(0, 2, 1))\n",
    "    dist += torch.sum(src**2, dim=-1).view(B, N, 1)\n",
    "    dist += torch.sum(dst**2, dim=-1).view(B, 1, M)\n",
    "\n",
    "    return dist\n",
    "\n",
    "\n",
    "def farthest_point_sample(xyz, npoint):\n",
    "    '''\n",
    "    Input:\n",
    "        xyz: [B, N, C]\n",
    "        npoint: Number of point for centered points\n",
    "    Return:\n",
    "        centered_idx: [B, npoint]\n",
    "    '''\n",
    "    B, N, C = xyz.shape\n",
    "    # [B, npoint]\n",
    "    centered_idx = torch.zeros(B, npoint, dtype=torch.long)\n",
    "    # [B]\n",
    "    farthest = torch.randint(0, N, (B, ), dtype=torch.long)\n",
    "    # [B, N]\n",
    "    distance = torch.ones(B, N) * 1e10\n",
    "    # [B]\n",
    "    batch_indices = torch.arange(0, B, dtype=torch.long)\n",
    "    for i in range(npoint):\n",
    "        centered_idx[:, i] = farthest\n",
    "        centered_xyz = xyz[batch_indices, farthest, :].view(B, 1, C)\n",
    "        dist = torch.sum((xyz - centered_xyz)**2, dim=-1)\n",
    "        # take the shortest distance as the distance from the remaining point\n",
    "        # set to the selected point set\n",
    "        # (if the point has been selected, the distance=0 is not updated)\n",
    "        mask = dist < distance\n",
    "        distance[mask] = dist[mask]\n",
    "        # update the farthest point by taking the index of the longest\n",
    "        # distance from the remaining point set to the selected point set\n",
    "        farthest = distance.max(-1)[1]\n",
    "\n",
    "    return centered_idx\n",
    "\n",
    "\n",
    "def index_points(points, idx):\n",
    "    '''\n",
    "    Input:\n",
    "        points: [B, N, D]\n",
    "        idx: [B, npoint, nsample]\n",
    "    Return:\n",
    "        new_points: [B, npoint, nsample, D]\n",
    "    '''\n",
    "    B, N, D = points.shape\n",
    "    view_list = list(idx.shape)\n",
    "    view_list[1:] = [1] * (len(view_list) - 1)\n",
    "    repeat_list = list(idx.shape)\n",
    "    repeat_list[0] = 1\n",
    "    batch_indices = torch.arange(B).view(view_list).repeat(repeat_list)\n",
    "    new_points = points[batch_indices, idx, :]\n",
    "\n",
    "    return new_points\n",
    "\n",
    "\n",
    "def query_ball_point(nsample, radius, xyz, centered_xyz):\n",
    "    '''\n",
    "    Input:\n",
    "        nsample: Number of point for each centered point/ball query\n",
    "        radius: Radius of the local query ball region\n",
    "        xyz: position data [B, N, C]\n",
    "        centered_xyz: position data of query points [B, npoint, C]\n",
    "    Return:\n",
    "        grouped_idx: indices of neighbouring points [B, npoint, nsample]\n",
    "    '''\n",
    "    B, N, C = xyz.shape\n",
    "    _, npoint, _ = centered_xyz.shape\n",
    "    # [B, npoint, nsample]\n",
    "    grouped_idx = torch.zeros(B, npoint, nsample, dtype=torch.long)\n",
    "    # [B, npiont, N]\n",
    "    distance = square_distance(centered_xyz, xyz)\n",
    "    # [B, npoint, N]\n",
    "    mask_N = distance > radius**2\n",
    "    # [B, npoint, N], assign a very large number (regarded as infinite) to all\n",
    "    # points outside the local ball region\n",
    "    distance[mask_N] = 1e10\n",
    "    # [B, npoint, nsample]\n",
    "    # take the first nsample closest points of each query(centered) point\n",
    "    # the numnber of local points might be less than nsample\n",
    "    grouped_idx = distance.sort(dim=-1)[1][..., :nsample]\n",
    "    # [B, npoint, nsample]\n",
    "    # duplicate the first point index\n",
    "    grouped_first = grouped_idx[..., 0].view(B, npoint,\n",
    "                                             1).repeat(1, 1, nsample)\n",
    "    # [B, npoint, nsample]\n",
    "    # mask the indices of points outside the local ball region\n",
    "    mask_nsample = distance.sort(dim=-1)[0][..., :nsample] == 1e10\n",
    "    # [B, npoint, nsample]\n",
    "    # assign the first point index to all the outside points\n",
    "    grouped_idx[mask_nsample] = grouped_first[mask_nsample]\n",
    "\n",
    "    return grouped_idx\n",
    "\n",
    "\n",
    "def sample_and_group(npoint, radius, nsample, points):\n",
    "    '''\n",
    "    Input:\n",
    "        npoint: Number of point for centered points (by FPS sampling)\n",
    "        radius: Radius of the local query ball region\n",
    "        nsample: Number of point for each centered point/ball query\n",
    "        points: position data and features [B, N, C+D]\n",
    "    Return:\n",
    "        centered_points: [B, npoint, C+D]\n",
    "        grouped_points: [B, npoint, nsample, C+D]\n",
    "    '''\n",
    "    # [B, N, C]\n",
    "    xyz = points[..., :3]\n",
    "    # [B, N, D]\n",
    "    features = points[..., 3:]\n",
    "    # [B, npoint]\n",
    "    centered_idx = farthest_point_sample(xyz, npoint)\n",
    "    # [B, npoint, C]\n",
    "    centered_xyz = index_points(xyz, centered_idx)\n",
    "    # [B, npoint, D]\n",
    "    centered_features = index_points(features, centered_idx)\n",
    "    # [B, npoint, C+D]\n",
    "    centered_points = torch.cat((centered_xyz, centered_features), dim=-1)\n",
    "\n",
    "    # [B, npoint, nsample]\n",
    "    grouped_idx = query_ball_point(nsample, radius, xyz, centered_xyz)\n",
    "    # [B, npoint, nsample, C]\n",
    "    grouped_xyz = index_points(xyz, grouped_idx)\n",
    "    # [B, npoint, nsample, D]\n",
    "    grouped_features = index_points(features, grouped_idx)\n",
    "    # [B, npoint, nsample, C+D]\n",
    "    grouped_points = torch.cat((grouped_xyz, grouped_features), dim=-1)\n",
    "\n",
    "    return centered_points, grouped_points\n",
    "\n",
    "\n",
    "def sample_and_group_all(points):\n",
    "    '''\n",
    "    This function takes all points as a group,\n",
    "    i.e., npoint = 1 and nsample = N.\n",
    "\n",
    "    Input:\n",
    "        points: [B, N, C+D]\n",
    "    Return:\n",
    "        centered_points: [B, 1, C+D]\n",
    "        grouped_points: [B, 1, N, C+D]\n",
    "    '''\n",
    "    B, N, _ = points.shape\n",
    "    # [B]\n",
    "    centered_idx = torch.randint(0, N, (B, ), dtype=torch.long)\n",
    "    # [B, 1, C+D]\n",
    "    centered_points = index_points(points, centered_idx).view(B, 1, -1)\n",
    "    # [B, 1, N, C+D]\n",
    "    grouped_points = points.view(B, 1, N, -1)\n",
    "\n",
    "    return centered_points, grouped_points\n",
    "\n",
    "\n",
    "class GraphAttention(nn.Module):\n",
    "    def __init__(self, all_channel, feature_channel):\n",
    "        super(GraphAttention, self).__init__()\n",
    "        # initialize a matrix to compute attention scores of\n",
    "        # each centered point and its neighbouring points\n",
    "        self.a = nn.Parameter(torch.zeros(all_channel, feature_channel))\n",
    "\n",
    "    def forward(self, centered_points, grouped_points):\n",
    "        '''\n",
    "        Input:\n",
    "            centered_points: [B, npoint, C+D]\n",
    "            grouped_points: [B, npoint, nsample, C+D]\n",
    "        Return:\n",
    "            centered_features: [B, npoint, D]\n",
    "        '''\n",
    "        B, npoint, nsample, dim = grouped_points.shape\n",
    "        # [B, npoint, nsample, D]\n",
    "        grouped_features = grouped_points[..., 3:]\n",
    "        # [B, npoint, nsample, C+D]\n",
    "        # compute the position and feature difference between\n",
    "        # the centered point and its neighbouring points\n",
    "        delta_p_concat_delta_h = grouped_points - centered_points.view(\n",
    "            B, npoint, 1, dim)\n",
    "        # [B, npoint, nsample, D]\n",
    "        attention = torch.matmul(delta_p_concat_delta_h, self.a)\n",
    "        # [B, npoint, nsample, D]\n",
    "        # normalize along each centered point's nsample neighbouring points\n",
    "        attention = attention.softmax(dim=2)\n",
    "        # [B, npoint, nsample, D]\n",
    "        # return weighted sum of each centered points by element-wise product\n",
    "        # of the computed attention scores and its responding neighbouring\n",
    "        # points' features, the output works as the centered_features for the\n",
    "        # next layer in GAC_Conv_layer\n",
    "        centered_features = torch.sum(torch.mul(attention, grouped_features),\n",
    "                                      dim=2)\n",
    "\n",
    "        return centered_features\n",
    "\n",
    "\n",
    "class GraphAttentionConvLayer(nn.Module):\n",
    "    def __init__(self, npoint, radius, nsample, mlp, feature_channel):\n",
    "        '''\n",
    "        Input:\n",
    "                npoint: Number of point for centered points (by FPS sampling)\n",
    "                radius: Radius of the local query ball region\n",
    "                nsample: Number of point for each centered point/ball query\n",
    "                mlp: A list for mlp input-output channel, e.g., [64, 64, 128]\n",
    "                feature_channel: the dimention of the input feature channel\n",
    "        '''\n",
    "        super(GraphAttentionConvLayer, self).__init__()\n",
    "        self.npoint = npoint\n",
    "        self.radius = radius\n",
    "        self.nsample = nsample\n",
    "        self.conv2ds = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "        last_channel = feature_channel\n",
    "        for out_channel in mlp:\n",
    "            self.conv2ds.append(nn.Conv2d(last_channel, out_channel, 1))\n",
    "            self.bns.append(nn.BatchNorm2d(out_channel))\n",
    "            last_channel = out_channel\n",
    "\n",
    "        self.GAC = GraphAttention(3 + last_channel, last_channel)\n",
    "\n",
    "    def forward(self, points):\n",
    "        '''\n",
    "        Input:\n",
    "            points: [B, N, C+D]\n",
    "        Return:\n",
    "            new_points: the centered points with position data and\n",
    "                        aggregated features from input points [B, npoint, C+D']\n",
    "        '''\n",
    "        B, N, _ = points.shape\n",
    "        # [B, npoint, C+D]\n",
    "        # [B, npoint, nsample, C+D]\n",
    "        centered_points, grouped_points = sample_and_group(\n",
    "            self.npoint, self.radius, self.nsample, points)\n",
    "        # [B, npoint, C]\n",
    "        centered_xyz = centered_points[..., :3]\n",
    "        # [B, D, 1, npoint]\n",
    "        # permute the dimensions for conv2d operation\n",
    "        centered_features = centered_points[..., 3:].view(\n",
    "            B, self.npoint, 1, -1).permute(0, 3, 2, 1)\n",
    "        # [B, npoint, nsample, C]\n",
    "        grouped_xyz = grouped_points[..., :3]\n",
    "        # [B, D, nsample, npoint]\n",
    "        grouped_features = grouped_points[..., 3:].permute(0, 3, 2, 1)\n",
    "\n",
    "        # map centered and grouped features into high-level ones,\n",
    "        # which have D' feature channels after the operation\n",
    "        for i, conv2d in enumerate(self.conv2ds):\n",
    "            bn = self.bns[i]\n",
    "            centered_features = bn(conv2d(centered_features))\n",
    "            grouped_features = bn(conv2d(grouped_features))\n",
    "\n",
    "        # [B, npoint, D']\n",
    "        centered_features = centered_features.permute(0, 3, 2, 1).squeeze()\n",
    "        # [B, npoint, nsample, D']\n",
    "        grouped_features = grouped_features.permute(0, 3, 2, 1)\n",
    "        # [B, npoint, C+D']\n",
    "        centered_points = torch.cat((centered_xyz, centered_features), dim=-1)\n",
    "        # [B, npoint, nsample, C+D']\n",
    "        grouped_points = torch.cat((grouped_xyz, grouped_features), dim=-1)\n",
    "        # [B, npoint, D']\n",
    "        # compute the aggregated features of each centered point\n",
    "        gac_features = self.GAC(centered_points, grouped_points)\n",
    "        # [B, npoint, C+D']\n",
    "        new_points = torch.cat((centered_xyz, gac_features), dim=-1)\n",
    "\n",
    "        return new_points\n",
    "\n",
    "\n",
    "class FeaturePropagationLayer(nn.Module):\n",
    "    def __init__(self, in_channel, mlp):\n",
    "        super(FeaturePropagationLayer, self).__init__()\n",
    "        self.conv1ds = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "        last_channel = in_channel\n",
    "        for out_channel in mlp:\n",
    "            self.conv1ds.append(nn.Conv1d(last_channel, out_channel, 1))\n",
    "            self.bns.append(nn.BatchNorm1d(out_channel))\n",
    "            last_channel = out_channel\n",
    "\n",
    "    def forward(self, layer1_points, layer2_points):\n",
    "        '''\n",
    "        Input:\n",
    "            points_1: input of a GAC_Layer [B, N, C + D_1]\n",
    "            points_2: output of the corresponding GAC_Layer\n",
    "                        [B, npoint, C + D_2]\n",
    "            N_1 >= N_2\n",
    "        Return:\n",
    "            new_points: [B, N, C + D_3]\n",
    "        '''\n",
    "        B, N, dim = layer1_points.shape\n",
    "        _, npoint, _ = layer2_points.shape\n",
    "        # [B, N, C]\n",
    "        layer1_xyz = layer1_points[..., :3]\n",
    "        # [B, N, D_1]\n",
    "        layer1_features = layer1_points[..., 3:]\n",
    "        # [B, npoint, C]\n",
    "        layer2_xyz = layer2_points[..., :3]\n",
    "        # [B, npoint, D_2]\n",
    "        layer2_features = layer2_points[..., 3:]\n",
    "        # if there is only one sampled point, copy the features of this point as the interpolated features\n",
    "        if npoint == 1:\n",
    "            # [B, N, D_2]\n",
    "            interpolated_features = layer2_features.repeat(1, N, 1)\n",
    "        # [B, N, npoint]\n",
    "        distance = square_distance(layer1_xyz, layer2_xyz)\n",
    "        # [B, N, npoint]\n",
    "        dist, idx = distance.sort(-1)\n",
    "        # [B, N, 3]\n",
    "        dist_knn = dist[..., :3]\n",
    "        # avoid dividing by 0\n",
    "        dist_knn[dist_knn < 1e10] = 1e-10\n",
    "        idx_knn = idx[..., :3]\n",
    "        # [B, N, 3]\n",
    "        weight = 1 / dist_knn\n",
    "        # [B, N, 3, D_2]\n",
    "        layer2_features_knn = index_points(layer2_features, idx_knn)\n",
    "        # [B, N, D_2]\n",
    "        interpolated_features = torch.sum(\n",
    "            torch.mul(weight.view(B, N, 3, 1), layer2_features_knn),\n",
    "            dim=-2) / torch.sum(weight, dim=-1).view(B, N, 1)\n",
    "        if dim == 3:\n",
    "            # [B, N, D_2]\n",
    "            new_features = interpolated_features\n",
    "        else:\n",
    "            # [B, N, D_1 + D_2]\n",
    "            new_features = torch.cat((layer1_features, interpolated_features), dim=-1)\n",
    "        new_features = new_features.permute(0, 2, 1)\n",
    "        for i, conv1d in enumerate(self.conv1ds):\n",
    "            bn = self.bns[i]\n",
    "            new_features = F.relu(bn(conv1d(new_features)))\n",
    "        # [B, N, C + D_3]\n",
    "        new_points = torch.cat((layer1_xyz, new_features.permute(0, 2, 1)), dim=-1)\n",
    "\n",
    "        return new_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([4, 100, 8, 9])"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "src = torch.ones(4, 5, 3, dtype=torch.long)\n",
    "dst = torch.arange(1, 25, dtype=torch.long).view(4,6,1).repeat(1,1,3)\n",
    "torch.manual_seed(4*4096*(3+6))\n",
    "xyz = torch.randn(4,4096,3)\n",
    "features = torch.randn(4,4096,6)\n",
    "points = torch.cat((xyz, features), dim=-1)\n",
    "npoint = 100\n",
    "nsample = 8\n",
    "radius = 2\n",
    "\n",
    "square_dist = square_distance(src, dst)\n",
    "centered_idx = farthest_point_sample(xyz, npoint)\n",
    "centered_xyz = index_points(xyz, centered_idx)\n",
    "grouped_idx = query_ball_point(nsample, radius, xyz, centered_xyz)\n",
    "grouped_xyz = index_points(xyz, grouped_idx)\n",
    "centered_points, grouped_points = sample_and_group(npoint, radius, nsample, points)\n",
    "grouped_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "layer1_points: torch.Size([4, 100, 35])\nlayer2_points: torch.Size([4, 25, 67])\n"
    }
   ],
   "source": [
    "layer1 = GraphAttentionConvLayer(npoint, radius, nsample, [16, 32], 6)\n",
    "layer2 = GraphAttentionConvLayer(int(npoint/4), radius, nsample, [32, 64], 32)\n",
    "layer1_points = layer1(points)\n",
    "layer2_points = layer2(layer1_points)\n",
    "print(f'layer1_points: {layer1_points.shape}\\nlayer2_points: {layer2_points.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([4, 100, 259])"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "fp1 = FeaturePropagationLayer(96, [128, 256])\n",
    "l1_point = fp1(layer1_points, layer2_points)\n",
    "l1_point.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAC_Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(GAC_Net, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        # GraphAttentionConvLayer(npoint, radius, nsample, mlp, feature_channel)\n",
    "        # [B, 1024, 32+3]\n",
    "        self.graph_pooling1 = GraphAttentionConvLayer(1024, 2, 32, [16, 32], 6)\n",
    "        # [B, 256, 128+3]\n",
    "        self.graph_pooling2 = GraphAttentionConvLayer(256, 2, 32, [64, 128], 32)\n",
    "        # [B, 64, 256+3]\n",
    "        self.graph_pooling3 = GraphAttentionConvLayer(64, 2, 32, [256, 256], 128)\n",
    "        # [B, 16, 512+3]\n",
    "        self.graph_pooling4 = GraphAttentionConvLayer(16, 2, 32, [512, 512], 256)\n",
    "        \n",
    "        # FeaturePropagationLayer(in_channel, mlp)\n",
    "        # in_channel = 256 + 512\n",
    "        self.fp4 = FeaturePropagationLayer(256 + 512, [256, 256])\n",
    "        # in_channel = 128 + 256\n",
    "        self.fp3 = FeaturePropagationLayer(128 + 256, [256, 128])\n",
    "        # in_channel = 32 + 128\n",
    "        self.fp2 = FeaturePropagationLayer(32 + 128, [128, 32])\n",
    "        # in_channel = 6 + 32\n",
    "        self.fp1 = FeaturePropagationLayer(6 + 32, [32, 32])\n",
    "\n",
    "        self.GAC_Layer = GraphAttentionConvLayer(4096, 2, 3, [32, 64], 32)\n",
    "\n",
    "        self.conv1d = nn.Conv1d(64+3, 32, 1)\n",
    "        self.bn = nn.BatchNorm1d(32)\n",
    "\n",
    "        self.fc = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, points):\n",
    "        # [B, 1024, 32+3]\n",
    "        layer1_points = self.graph_pooling1(points)\n",
    "        # [B, 256, 128+3]\n",
    "        layer2_points = self.graph_pooling2(layer1_points)\n",
    "        # [B, 64, 256+3]\n",
    "        layer3_points = self.graph_pooling3(layer2_points)\n",
    "        # [B, 16, 512+3]\n",
    "        layer4_points = self.graph_pooling4(layer3_points)\n",
    "\n",
    "        # [B, 64, 256+3]\n",
    "        layer3_points = self.fp4(layer3_points, layer4_points)\n",
    "        # [B, 256, 128+3]\n",
    "        layer2_points = self.fp3(layer2_points, layer3_points)\n",
    "        # [B, 1024, 32+3]\n",
    "        layer1_points = self.fp2(layer1_points, layer2_points)\n",
    "        # [B, 4096, 32+3]\n",
    "        layer0_points = self.fp1(points, layer1_points)\n",
    "        # [B, 4096, 64+3]\n",
    "        layer0_points = self.GAC_Layer(layer0_points)\n",
    "        # [B, 32, 4096]\n",
    "        layer0_points = F.relu(self.bn(self.conv1d(layer0_points.permute(0,2,1))))\n",
    "        # [B, 4096, num_classes]\n",
    "        layer0_points = self.fc(layer0_points.permute(0,2,1))\n",
    "        layer0_points = layer0_points.softmax(-1)\n",
    "        \n",
    "        return layer0_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GAC_Net(13)\n",
    "gp = net(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([4, 4096])"
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "class_id = gp.max(-1)[1]\n",
    "class_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}