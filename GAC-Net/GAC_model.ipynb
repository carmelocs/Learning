{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596974196548",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_distance(src, dst):\n",
    "    '''\n",
    "    Compute the distances between each point from src to dst\n",
    "    src^T * dst = xn * xm + yn * ym + zn * zmï¼›\n",
    "    sum(src^2, dim=-1) = xn*xn + yn*yn + zn*zn;\n",
    "    sum(dst^2, dim=-1) = xm*xm + ym*ym + zm*zm;\n",
    "    dist = (xn - xm)^2 + (yn - ym)^2 + (zn - zm)^2\n",
    "         = sum(src**2,dim=-1)+sum(dst**2,dim=-1)-2*src^T*dst\n",
    "    Input:\n",
    "        src: [B, N, C]\n",
    "        dst: [B, M, C]\n",
    "    Return:\n",
    "        dist: [B, N, M]\n",
    "    '''\n",
    "    B, N, C = src.shape\n",
    "    _, M, _ = dst.shape\n",
    "    # [B, N, M]\n",
    "    # -2*(xn * xm + yn * ym + zn * zm)\n",
    "    dist = -2*torch.matmul(src, dst.permute(0,2,1))\n",
    "    # sum(src^2, dim=-1) = xn*xn + yn*yn + zn*zn\n",
    "    dist += torch.sum(src**2, dim=-1).view(B,N,1)\n",
    "    # sum(dst^2, dim=-1) = xm*xm + ym*ym + zm*zm\n",
    "    dist += torch.sum(dst**2, dim=-1).view(B,1,M)\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([4, 5, 6])"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "src = torch.arange(20).view(4,5,1).repeat(1,1,3).long()\n",
    "dst = torch.arange(24).view(4,6,1).repeat(1,1,3).long()\n",
    "dist = torch.zeros(4,5,6)\n",
    "# dist = -2*torch.matmul(src, dst.permute(0,2,1))\n",
    "# dist += torch.sum(src**2, dim=-1).view(4,5,1)\n",
    "# dist += torch.sum(dst**2, dim=-1).view(4,1,6)\n",
    "dist = square_distance(src, dst)\n",
    "dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def farthest_point_sample(xyz, npoint):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        xyz: pointcloud data, [B, N, C]\n",
    "        npoint: number of centroids\n",
    "    Return:\n",
    "        centered_idx: sampled pointcloud index, [B, npoint]\n",
    "    \"\"\"\n",
    "    B, N, C = xyz.shape\n",
    "    # print(f'B: {B}\\nN: {N}\\nC: {C}')\n",
    "    centered_idx = torch.zeros(B, npoint, dtype=torch.long)\n",
    "    distance = torch.ones(B, N)*1e10\n",
    "    farthest = torch.randint(0, N, (B,), dtype=torch.long)\n",
    "    batch_indices = torch.arange(0, B, dtype=torch.long)\n",
    "    for i in range(npoint):\n",
    "        # [B, npoint]\n",
    "        centered_idx[:,i] = farthest\n",
    "        # [B, 1, C]\n",
    "        centroid = xyz[batch_indices, farthest, :].view(B,1,C)\n",
    "        dist = square_distance(xyz, centroid).squeeze()\n",
    "        mask = dist < distance\n",
    "        distance[mask] = dist[mask]\n",
    "        farthest = distance.max(dim=-1)[1]\n",
    "\n",
    "    return centered_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([4, 5])"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "xyz = torch.randn(4,20,3)\n",
    "npoint = 5\n",
    "\n",
    "centered_idx = farthest_point_sample(xyz, npoint)\n",
    "centered_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_points(points, idx):\n",
    "    '''\n",
    "    Input:\n",
    "        points: [B, N, C or D]\n",
    "        idx: [B, npoint] or [B, npoint, nsample]...\n",
    "    Return:\n",
    "        new_points: [B, npoint, C or D] or [B, npoint, nsample, C or D]...\n",
    "    '''\n",
    "    B, N, C = points.shape\n",
    "    view_list = list(idx.shape)\n",
    "    view_list[1:] = [1]*(len(view_list)-1)\n",
    "    repeat_list = list(idx.shape)\n",
    "    repeat_list[0] = 1\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).view(view_list).repeat(repeat_list)\n",
    "    new_points = points[batch_indices, idx, :]\n",
    "    return new_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([4, 5, 9])"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "points = torch.randn(4,20,9)\n",
    "npoint = 5\n",
    "idx = farthest_point_sample(points, 5)\n",
    "\n",
    "new_points = index_points(points, idx)\n",
    "new_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_ball_point(radius, nsample, xyz, centered_xyz):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        radius: local region radius\n",
    "        nsample: max sample number in local region\n",
    "        xyz: all points, [B, N, C]\n",
    "        centered_xyz: query points, [B, npoint, C]\n",
    "    Return:\n",
    "        grouped_idx: grouped points index, [B, npoint, nsample]\n",
    "    \"\"\"\n",
    "    B, N, C = xyz.shape\n",
    "    _, npoint, _ = centered_xyz.shape\n",
    "    # [B, npoint, N]\n",
    "    # initialize the grouped_idx containing all N points for each sampled point\n",
    "    grouped_idx = torch.arange(N, dtype=torch.long).view(1,1,N).repeat(B, npoint, 1)\n",
    "    # [B, npoint, N]\n",
    "    # record the square distance from the sampled points to all N points\n",
    "    distance = square_distance(centered_xyz, xyz)\n",
    "    # [B, npoint, N]\n",
    "    # a mask finding all points outside the local region (ball area radius^2)\n",
    "    mask_1 = distance > radius**2\n",
    "    # [B, npoint, N]\n",
    "    # assign a large number(1e10) to the outside points\n",
    "    distance[mask_1] = 1e10\n",
    "    # [B, npoint, nsample]\n",
    "    # select nsample sorted grouped_idx by distances, it may contain outside points\n",
    "    grouped_idx = distance.sort(dim=-1)[1][:,:,:nsample]\n",
    "    # [B, npoint, nsample]\n",
    "    # duplicate the first point in each local region\n",
    "    grouped_first = grouped_idx[:,:,0].view(B, npoint, 1).repeat(1,1,nsample)\n",
    "    # [B, npoint, nsample]\n",
    "    # a mask finding all outside points in the sampled distance matrix\n",
    "    mask_2 = distance.sort(dim=-1)[0][:,:,:nsample]==1e10\n",
    "    # [B, npoint, nsample]\n",
    "    # assign the first point to all outside points in grouped_idx\n",
    "    grouped_idx[mask_2] = grouped_first[mask_2]\n",
    "\n",
    "    return grouped_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[11,  1, 17, 14, 11, 11, 11, 11, 11, 11],\n         [19,  9, 12,  7, 13, 15,  4,  6, 16, 19],\n         [10,  3, 10, 10, 10, 10, 10, 10, 10, 10],\n         [ 8,  1,  8,  8,  8,  8,  8,  8,  8,  8],\n         [18,  4, 16,  0,  3,  5,  6, 14, 15, 12]],\n\n        [[ 8, 14, 13,  4, 15,  5,  0, 11, 18, 19],\n         [12,  2, 16,  6, 12, 12, 12, 12, 12, 12],\n         [ 6, 16,  7, 14, 18, 13, 12,  5,  2,  8],\n         [ 3, 15,  9,  4,  8, 11,  0, 17,  5, 10],\n         [17,  1, 10,  0, 19,  8, 13,  4,  3, 11]],\n\n        [[11,  6, 13,  7,  1, 16,  5, 11, 11, 11],\n         [17, 18,  8, 17, 17, 17, 17, 17, 17, 17],\n         [14, 15, 19, 10,  2,  5, 14, 14, 14, 14],\n         [12,  2,  5, 19, 15, 12, 12, 12, 12, 12],\n         [ 3,  4,  7,  3,  3,  3,  3,  3,  3,  3]],\n\n        [[13, 10, 12, 15, 13, 13, 13, 13, 13, 13],\n         [ 2,  0, 16, 19,  8,  5,  2,  2,  2,  2],\n         [ 1,  7,  1,  1,  1,  1,  1,  1,  1,  1],\n         [14, 11,  4, 17,  9,  8, 18, 12,  0, 14],\n         [ 3, 10,  3,  3,  3,  3,  3,  3,  3,  3]]])"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "torch.manual_seed(4*20*3)\n",
    "xyz = torch.randn(4,20,3)\n",
    "npoint = 5\n",
    "nsample = 10\n",
    "radius = 2\n",
    "centered_idx = farthest_point_sample(xyz, npoint)\n",
    "centered_xyz = index_points(xyz, centered_idx)\n",
    "\n",
    "grouped_idx = query_ball_point(radius, nsample, xyz, centered_xyz)\n",
    "grouped_xyz = index_points(xyz, grouped_idx)\n",
    "grouped_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_group(npoint, radius, nsample, xyz, features):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        npoint: Number of point for FPS\n",
    "        radius: Radius of ball query\n",
    "        nsample: Number of point for each ball query\n",
    "        xyz: input points position data, [B, N, C]\n",
    "        features: input points data, [B, N, D]\n",
    "    Return:\n",
    "        centered_points: sampled points data, [B, npoint, C+D]\n",
    "        grouped_points: sampled points data, [B, npoint, nsample, C+D]\n",
    "    \"\"\"\n",
    "    B, N, C = xyz.shape\n",
    "    # [B, npoint]\n",
    "    centered_idx = farthest_point_sample(xyz, npoint)\n",
    "    # [B, npoint, C]\n",
    "    centered_xyz = index_points(xyz, centered_idx)\n",
    "    # [B, npoint, nsample]\n",
    "    grouped_idx = query_ball_point(radius, nsample, xyz, centered_xyz)\n",
    "    # [B, npoint, nsample, C]\n",
    "    grouped_xyz = index_points(xyz, grouped_idx)\n",
    "    # [B, npoint, nsample, C]\n",
    "    grouped_xyz_norm = grouped_xyz - centered_xyz.view(B, npoint, 1, C)\n",
    "    if features is not None:\n",
    "        centered_features = index_points(features, centered_idx)\n",
    "        centered_points = torch.cat((centered_xyz, centered_features), dim=-1)\n",
    "        grouped_features = index_points(features, grouped_idx)\n",
    "        grouped_points = torch.cat((grouped_xyz_norm, grouped_features), dim=-1)\n",
    "    else:\n",
    "        centered_points = centered_xyz\n",
    "        grouped_points = grouped_xyz\n",
    "    return centered_points, grouped_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([4, 5, 10, 9])"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "torch.manual_seed(4*20*(3+6))\n",
    "xyz = torch.randn(4,20,3)\n",
    "features = torch.randn(4,20,6)\n",
    "B = 4\n",
    "npoint = 5\n",
    "nsample = 10\n",
    "radius = 2\n",
    "\n",
    "centered_points, grouped_points = sample_and_group(npoint, radius, nsample, xyz, features)\n",
    "grouped_points.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all points as a group\n",
    "# npoint = 1\n",
    "# nsample = N\n",
    "def sample_and_group_all(xyz, features):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        xyz: input points position data, [B, N, C]\n",
    "        features: input points data, [B, N, D]\n",
    "    Return:\n",
    "        centered_points: sampled points position data, [B, 1, C+D]\n",
    "        grouped_points: sampled points data, [B, 1, N, C+D]\n",
    "    \"\"\"\n",
    "    B, N, C = xyz.shape\n",
    "    npoint = 1\n",
    "    nsample = N\n",
    "    centered_idx = farthest_point_sample(xyz, npoint)\n",
    "    centered_xyz = index_points(xyz, centered_idx)\n",
    "    grouped_xyz = xyz.view(B, npoint, nsample, C)\n",
    "    if features is not None:\n",
    "        centered_features = index_points(features, centered_idx)\n",
    "        centered_points = torch.cat((centered_xyz, centered_features), dim=-1)\n",
    "        grouped_features = features.view(B, npoint, nsample, -1)\n",
    "        grouped_points = torch.cat((grouped_xyz, grouped_features), dim=-1)\n",
    "    else:\n",
    "        centered_points = centered_xyz\n",
    "        grouped_points = grouped_xyz\n",
    "    return centered_points, grouped_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([4, 1, 20, 9])"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "torch.manual_seed(4*20*(3+6))\n",
    "xyz = torch.randn(4,20,3)\n",
    "features = torch.randn(4,20,6)\n",
    "radius = 2\n",
    "\n",
    "centered_points, grouped_points = sample_and_group_all(xyz, features)\n",
    "grouped_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphAttention(nn.Module):\n",
    "    def __init__(self, all_channel, feature_channel, dropout, alpha):\n",
    "        super(GraphAttention, self).__init__()\n",
    "        self.a = nn.Parameter(torch.zeros(all_channel, feature_channel))\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "        self.dropout = dropout\n",
    "        self.alpha = alpha\n",
    "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
    "\n",
    "    def forward(self, centered_points, grouped_points):\n",
    "        '''\n",
    "        Input:\n",
    "            centered_points: centered point position data and feature [B, npoint, C+D]\n",
    "            grouped_points: sampled points position data and feature [B, npoint, nsample, C+D]\n",
    "        Return:\n",
    "            centered_xyz: centered point position data [B, npoint, C]\n",
    "            centered_h: learned centered_features [B, npoint, D]\n",
    "        '''\n",
    "        # [B, npoint, C]\n",
    "        centered_xyz = centered_points[...,:3]\n",
    "        # [B, npoint, nsample, C]\n",
    "        grouped_xyz = grouped_points[...,:3]\n",
    "        # [B, npoint, D]\n",
    "        centered_features = centered_points[...,3:]\n",
    "        # [B, npoint, nsample, D]\n",
    "        grouped_features = grouped_points[...,3:]\n",
    "\n",
    "        B, npoint, C = centered_xyz.shape\n",
    "        _, _, nsample, _ = grouped_xyz.shape\n",
    "        _, _, D = centered_features.shape\n",
    "\n",
    "        # # compute the position difference between the centered point and its neighbouring points, [B, npoint, nsample, C]\n",
    "        # delta_p = grouped_xyz - centered_xyz.view(B, npoint, 1, C)\n",
    "        # # compute the feature difference between the centered point and its neighbouring points, [B, npoint, nsample, D]\n",
    "        # delta_h = grouped_features - centered_features.view(B, npoint, 1, D)\n",
    "        # # concatenate the position data of delta_p and the feature of delta_h, [B, npoint, nsample, C+D]\n",
    "        # delta_p_concat_delta_h = torch.cat((delta_p, delta_h), dim=-1)\n",
    "\n",
    "        # compute the position and feature difference between the centered point and its neighbouring points, [B, npoint, nsample, C+D]\n",
    "        delta_points = grouped_points - centered_points.view(B, npoint, 1, -1)\n",
    "        # compute attention scores between each centered point and its neighbouring points by a MLP: [C+D, D]\n",
    "        # [B, npoint, nsample, D]\n",
    "        attention = self.leakyrelu(torch.matmul(delta_points, self.a))\n",
    "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
    "        # normalize each centered point's attention scores with all its neighbouring points\n",
    "        attention = attention.softmax(2)\n",
    "        # return weighted sum of each centered points by element-wise product of the computed attention scores and its responding neighbouring points' features, the output works as the centered_features for the next layer\n",
    "        # [B, npoint, D]\n",
    "        centered_h = torch.sum(torch.mul(attention, grouped_features), dim=2)\n",
    "\n",
    "        return centered_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "all_channel: 9\nfeature_channel: 6\n\ncentered_xyz: torch.Size([4, 5, 3])\ngrouped_xyz: torch.Size([4, 5, 10, 3])\ncentered_features: torch.Size([4, 5, 6])\ngrouped_features: torch.Size([4, 5, 10, 6])\n"
    }
   ],
   "source": [
    "torch.manual_seed(4*20*(3+6))\n",
    "xyz = torch.randn(4,20,3)\n",
    "features = torch.randn(4,20,6)\n",
    "npoint = 5\n",
    "nsample = 10\n",
    "radius = 2\n",
    "\n",
    "all_channel = xyz.shape[-1] + features.shape[-1]\n",
    "feature_channel = features.shape[-1]\n",
    "print(f'all_channel: {all_channel}\\nfeature_channel: {feature_channel}\\n')\n",
    "\n",
    "centered_points, grouped_points = sample_and_group(npoint, radius, nsample, xyz, features)\n",
    "centered_xyz = centered_points[...,:3]\n",
    "grouped_xyz = grouped_points[...,:3]\n",
    "centered_features = centered_points[...,3:]\n",
    "grouped_features = grouped_points[...,3:]\n",
    "\n",
    "print(f\"centered_xyz: {centered_xyz.shape}\\ngrouped_xyz: {grouped_xyz.shape}\\ncentered_features: {centered_features.shape}\\ngrouped_features: {grouped_features.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([4, 5, 6])"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "GAC = GraphAttention(all_channel, feature_channel, dropout=0.5, alpha=0.2)\n",
    "centered_h = GAC(centered_points, grouped_points)\n",
    "centered_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphAttentionConvLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 npoint,\n",
    "                 radius,\n",
    "                 nsample,\n",
    "                 feature_channel,\n",
    "                 mlp,\n",
    "                 group_all,\n",
    "                 dropout=0.6,\n",
    "                 alpha=0.2):\n",
    "        '''\n",
    "        Input:\n",
    "                npoint: Number of point for FPS sampling\n",
    "                radius: Radius for ball query\n",
    "                nsample: Number of point for each ball query\n",
    "                feature_channel: the dimention of the input feature channel\n",
    "                mlp: A list for mlp input-output channel, such as [64, 64, 128]\n",
    "                group_all: bool type for group_all or not\n",
    "        '''\n",
    "\n",
    "        super(GraphAttentionConvLayer, self).__init__()\n",
    "        self.npoint = npoint\n",
    "        self.radius = radius\n",
    "        self.nsample = nsample\n",
    "        self.group_all = group_all\n",
    "        self.dropout = dropout\n",
    "        self.alpha = alpha\n",
    "        self.conv2ds = nn.ModuleList()\n",
    "        self.bn2ds = nn.ModuleList()\n",
    "        last_channel = feature_channel\n",
    "        for out_channel in mlp:\n",
    "            self.conv2ds.append(nn.Conv2d(last_channel, out_channel, 1))\n",
    "            self.bn2ds.append(nn.BatchNorm2d(out_channel))\n",
    "            last_channel = out_channel\n",
    "        self.GAC = GraphAttention(3 + last_channel, last_channel, dropout=self.dropout, alpha=self.alpha)\n",
    "\n",
    "    def forward(self, points):\n",
    "        '''\n",
    "        Input:\n",
    "            points: position data and features [B, N, C+D]\n",
    "        Return:\n",
    "            sampled_points: sampled position data and aggregated features [B, npoint, 3+D']\n",
    "        '''\n",
    "        xyz = points[...,:3]\n",
    "        features = points[...,3:]\n",
    "        centered_points, grouped_points = sample_and_group(self.npoint, self.radius, self.nsample, xyz, features)\n",
    "        centered_xyz = centered_points[...,:3]\n",
    "        grouped_xyz = grouped_points[...,:3]\n",
    "        centered_features = centered_points[...,3:]\n",
    "        grouped_features = grouped_points[...,3:]\n",
    "\n",
    "        centered_features = centered_features.unsqueeze(2).permute(0,3,2,1)\n",
    "        grouped_features = grouped_features.permute(0,3,2,1)\n",
    "        for i, conv2d in enumerate(self.conv2ds):\n",
    "            bn2d = self.bn2ds[i]\n",
    "            centered_features = F.relu(bn2d(conv2d(centered_features)))\n",
    "            grouped_features = F.relu(bn2d(conv2d(grouped_features)))\n",
    "        \n",
    "        centered_features = centered_features.permute(0,3,2,1).squeeze()\n",
    "        grouped_features = grouped_features.permute(0,3,2,1)\n",
    "        centered_points = torch.cat((centered_xyz, centered_features), dim=-1)\n",
    "        grouped_points = torch.cat((grouped_xyz, grouped_features), dim=-1)\n",
    "        sampled_features = self.GAC(centered_points, grouped_points)\n",
    "        sampled_points = torch.cat((centered_xyz, sampled_features), dim=-1)\n",
    "        return sampled_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([4, 4, 67])"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "torch.manual_seed(4*20*(3+6))\n",
    "xyz = torch.randn(4,20,3)\n",
    "features = torch.randn(4,20,6)\n",
    "points = torch.cat((xyz, features), dim=-1)\n",
    "npoint = 5\n",
    "nsample = 10\n",
    "radius = 2\n",
    "feature_channel = features.shape[-1]\n",
    "\n",
    "GAC_Layer1 = GraphAttentionConvLayer(npoint, radius, nsample, feature_channel, [16, 32], False)\n",
    "GAC_Layer2 = GraphAttentionConvLayer(4, 1, 5, 32, [32, 64], False)\n",
    "layer1_points = GAC_Layer1(points)\n",
    "layer2_points = GAC_Layer2(layer1_points)\n",
    "layer2_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}